{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week3.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mrinal18/Siraj_Tutorial/blob/master/Week3/Week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xlab_-_gS2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import lightgbm as lgb\n",
        "from sklearn import metrics\n",
        "import gc\n",
        "from time import time\n",
        "import datetime\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold,GroupKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "warnings.simplefilter('ignore')\n",
        "sns.set()\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3IbO5dZgZAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'xx'\n",
        "os.environ['KAGGLE_KEY'] = 'xxx'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLKDrp-qoJ_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " !pip install -q kaggle\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QORIjDn7ofpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip sample_submission.csv.zip\n",
        "!unzip train_transaction.csv.zip\n",
        "!unzip train_identity.csv.zip\n",
        "!unzip test_transaction.csv.zip\n",
        "!unzip test_identity.csv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf9AZBcroJv9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHsKrugzisED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8TMzi7BinZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%time\n",
        "warnings.simplefilter('ignore')\n",
        "files = ['test_identity.csv', \n",
        "         'test_transaction.csv',\n",
        "         'train_identity.csv',\n",
        "         'train_transaction.csv',\n",
        "         'sample_submission.csv']\n",
        "\n",
        "def load_data(file):\n",
        "    return reduce_mem_usage(pd.read_csv(file))\n",
        "\n",
        "with multiprocessing.Pool() as pool:\n",
        "    test_identity, test_transaction, train_identity, train_transaction, sample_submission = pool.map(load_data, files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdjIO0aAmHJ3",
        "colab_type": "text"
      },
      "source": [
        "##Visualize the DatasetÂ¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1-CWQiijadR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transaction['TransactionAmt'] = train_transaction['TransactionAmt'].astype(float)\n",
        "total = len(train_transaction)\n",
        "total_amt = train_transaction.groupby(['isFraud'])['TransactionAmt'].sum().sum()\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(121)\n",
        "plot_tr = sns.countplot(x='isFraud', data=train_transaction)\n",
        "plot_tr.set_title(\"Fraud Transactions Distribution \\n 0: No Fraud | 1: Fraud\", fontsize=18)\n",
        "plot_tr.set_xlabel(\"Is fraud?\", fontsize=16)\n",
        "plot_tr.set_ylabel('Count', fontsize=16)\n",
        "for p in plot_tr.patches:\n",
        "    height = p.get_height()\n",
        "    plot_tr.text(p.get_x()+p.get_width()/2.,\n",
        "            height + 3,\n",
        "            '{:1.2f}%'.format(height/total*100),\n",
        "            ha=\"center\", fontsize=15) \n",
        "    \n",
        "percent_amt = (train_transaction.groupby(['isFraud'])['TransactionAmt'].sum())\n",
        "percent_amt = percent_amt.reset_index()\n",
        "plt.subplot(122)\n",
        "plot_tr_2 = sns.barplot(x='isFraud', y='TransactionAmt',  dodge=True, data=percent_amt)\n",
        "plot_tr_2.set_title(\"% Total Amount in Transaction Amt \\n 0: No Fraud | 1: Fraud\", fontsize=18)\n",
        "plot_tr_2.set_xlabel(\"Is fraud?\", fontsize=16)\n",
        "plot_tr_2.set_ylabel('Total Transaction Amount Scalar', fontsize=16)\n",
        "for p in plot_tr_2.patches:\n",
        "    height = p.get_height()\n",
        "    plot_tr_2.text(p.get_x()+p.get_width()/2.,\n",
        "            height + 3,\n",
        "            '{:1.2f}%'.format(height/total_amt * 100),\n",
        "            ha=\"center\", fontsize=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPXzMdb7mMnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(16,12))\n",
        "plt.suptitle('Transaction Values Distribution', fontsize=22)\n",
        "plt.subplot(221)\n",
        "sub_plot_1 = sns.distplot(train_transaction[train_transaction['TransactionAmt'] <= 1000]['TransactionAmt'])\n",
        "sub_plot_1.set_title(\"Transaction Amount Distribuition <= 1000\", fontsize=18)\n",
        "sub_plot_1.set_xlabel(\"\")\n",
        "sub_plot_1.set_ylabel(\"Probability\", fontsize=15)\n",
        "\n",
        "plt.subplot(222)\n",
        "sub_plot_2 = sns.distplot(np.log(train_transaction['TransactionAmt']))\n",
        "sub_plot_2.set_title(\"Transaction Amount (Log) Distribuition\", fontsize=18)\n",
        "sub_plot_2.set_xlabel(\"\")\n",
        "sub_plot_2.set_ylabel(\"Probability\", fontsize=15)\n",
        "\n",
        "plt.figure(figsize=(16,12))\n",
        "\n",
        "\n",
        "plt.subplot(212)\n",
        "sub_plot_3 = plt.scatter(range(train_transaction[train_transaction['isFraud'] == 0].shape[0]),\n",
        "                 np.sort(train_transaction[train_transaction['isFraud'] == 0]['TransactionAmt'].values), \n",
        "                 label='NoFraud', alpha=.2)\n",
        "sub_plot_3 = plt.scatter(range(train_transaction[train_transaction['isFraud'] == 1].shape[0]),\n",
        "                 np.sort(train_transaction[train_transaction['isFraud'] == 1]['TransactionAmt'].values), \n",
        "                 label='Fraud', alpha=.2)\n",
        "sub_plot_3= plt.title(\"ECDF \\nFRAUD and NO FRAUD Transaction Amount Distribution\", fontsize=18)\n",
        "sub_plot_3 = plt.xlabel(\"Index\")\n",
        "sub_plot_3 = plt.ylabel(\"Amount Distribution\", fontsize=15)\n",
        "sub_plot_3 = plt.legend()\n",
        "\n",
        "plt.figure(figsize=(16,12))\n",
        "\n",
        "plt.subplot(321)\n",
        "sub_plot_4 = plt.scatter(range(train_transaction[train_transaction['isFraud'] == 1].shape[0]), \n",
        "                 np.sort(train_transaction[train_transaction['isFraud'] == 1]['TransactionAmt'].values), \n",
        "                label='isFraud', alpha=.4)\n",
        "plt.title(\"FRAUD - Transaction Amount ECDF\", fontsize=18)\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amount Distribution\", fontsize=12)\n",
        "\n",
        "plt.subplot(322)\n",
        "sub_plot_5 = plt.scatter(range(train_transaction[train_transaction['isFraud'] == 0].shape[0]),\n",
        "                 np.sort(train_transaction[train_transaction['isFraud'] == 0]['TransactionAmt'].values), \n",
        "                 label='NoFraud', alpha=.2)\n",
        "sub_plot_5 = plt.title(\"NO FRAUD - Transaction Amount ECDF\", fontsize=18)\n",
        "sub_plot_5 = plt.xlabel(\"Index\")\n",
        "sub_plot_5 = plt.ylabel(\"Amount Distribution\", fontsize=15)\n",
        "\n",
        "plt.suptitle('Individual ECDF Distribution', fontsize=20)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjCx0x4cpqzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = pd.crosstab(train_transaction['ProductCD'], train_transaction['isFraud'], normalize='index') * 100\n",
        "tmp = tmp.reset_index()\n",
        "tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
        "\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.suptitle('ProductCD Distributions', fontsize=22)\n",
        "\n",
        "plt.subplot(221)\n",
        "plot_1 = sns.countplot(x='ProductCD', data=train_transaction)\n",
        "# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n",
        "\n",
        "plot_1.set_title(\"ProductCD Distribution\", fontsize=18)\n",
        "plot_1.set_xlabel(\"ProductCD Name\", fontsize=16)\n",
        "plot_1.set_ylabel(\"Count\", fontsize=17)\n",
        "plot_1.set_ylim(0,500000)\n",
        "for p in plot_1.patches:\n",
        "    height = p.get_height()\n",
        "    plot_1.text(p.get_x()+p.get_width()/2.,\n",
        "            height + 3,\n",
        "            '{:1.2f}%'.format(height/total*100),\n",
        "            ha=\"center\", fontsize=14) \n",
        "\n",
        "plt.subplot(222)\n",
        "plot_2 = sns.countplot(x='ProductCD', hue='isFraud', data=train_transaction)\n",
        "plt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\n",
        "plot_2_2 = plot_2.twinx()\n",
        "plot_2_2 = sns.pointplot(x='ProductCD', y='Fraud', data=tmp, color='black', order=['W', 'H',\"C\", \"S\", \"R\"], legend=False)\n",
        "plot_2_2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n",
        "\n",
        "plot_2.set_title(\"Product CD by Target(isFraud)\", fontsize=18)\n",
        "plot_2.set_xlabel(\"ProductCD Name\", fontsize=16)\n",
        "plot_2.set_ylabel(\"Count\", fontsize=16)\n",
        "\n",
        "plt.subplot(212)\n",
        "plot_3 = sns.boxenplot(x='ProductCD', y='TransactionAmt', hue='isFraud', \n",
        "              data=train_transaction[train_transaction['TransactionAmt'] <= 2000] )\n",
        "plot_3.set_title(\"Transaction Amount Distribuition by ProductCD and Target\", fontsize=18)\n",
        "plot_3.set_xlabel(\"ProductCD Name\", fontsize=16)\n",
        "plot_3.set_ylabel(\"Transaction Values\", fontsize=16)\n",
        "\n",
        "plt.subplots_adjust(hspace = 0.6, top = 0.85)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZmqSjrhpvBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transaction.loc[train_transaction.card3.isin(train_transaction.card3.value_counts()[train_transaction.card3.value_counts() < 200].index), 'card3'] = \"Others\"\n",
        "train_transaction.loc[train_transaction.card5.isin(train_transaction.card5.value_counts()[train_transaction.card5.value_counts() < 300].index), 'card5'] = \"Others\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "065MUkwxp1fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = pd.crosstab(train_transaction['card3'], train_transaction['isFraud'], normalize='index') * 100\n",
        "tmp = tmp.reset_index()\n",
        "tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
        "\n",
        "tmp2 = pd.crosstab(train_transaction['card5'], train_transaction['isFraud'], normalize='index') * 100\n",
        "tmp2 = tmp2.reset_index()\n",
        "tmp2.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
        "\n",
        "plt.figure(figsize=(14,22))\n",
        "\n",
        "plt.subplot(411)\n",
        "plot_1 = sns.distplot(train_transaction[train_transaction['isFraud'] == 1]['card1'], label='Fraud')\n",
        "plot_1 = sns.distplot(train_transaction[train_transaction['isFraud'] == 0]['card1'], label='NoFraud')\n",
        "plot_1.legend()\n",
        "plot_1.set_title(\"Card 1 Values Distribution by Target\", fontsize=20)\n",
        "plot_1.set_xlabel(\"Card 1 Values\", fontsize=18)\n",
        "plot_1.set_ylabel(\"Probability\", fontsize=18)\n",
        "\n",
        "plt.subplot(412)\n",
        "plot_2 = sns.distplot(train_transaction[train_transaction['isFraud'] == 1]['card2'].dropna(), label='Fraud')\n",
        "plot_2 = sns.distplot(train_transaction[train_transaction['isFraud'] == 0]['card2'].dropna(), label='NoFraud')\n",
        "plot_2.legend()\n",
        "plot_2.set_title(\"Card 2 Values Distribution by Target\", fontsize=20)\n",
        "plot_2.set_xlabel(\"Card 2 Values\", fontsize=18)\n",
        "plot_2.set_ylabel(\"Probability\", fontsize=18)\n",
        "\n",
        "plt.subplot(413)\n",
        "plot_3 = sns.countplot(x='card3', data=train_transaction, order=list(tmp.card3.values))\n",
        "plot_3_2 = plot_3.twinx()\n",
        "plot_3_2 = sns.pointplot(x='card3', y='Fraud', data=tmp, \n",
        "                    color='black', order=list(tmp.card3.values))\n",
        "plot_3_2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n",
        "plot_3.set_title(\"Card 3 Values Distribution and % of Transaction Frauds\", fontsize=20)\n",
        "plot_3.set_xlabel(\"Card 3 Values\", fontsize=18)\n",
        "plot_3.set_ylabel(\"Count\", fontsize=18)\n",
        "for p in plot_3.patches:\n",
        "    height = p.get_height()\n",
        "    plot_3.text(p.get_x()+p.get_width()/2.,\n",
        "            height + 25,\n",
        "            '{:1.2f}%'.format(height/total*100),\n",
        "            ha=\"center\") \n",
        "\n",
        "plt.subplot(414)\n",
        "plot_4 = sns.countplot(x='card5', data=train_transaction, order=list(tmp2.card5.values))\n",
        "plot_4_2 = plot_4.twinx()\n",
        "plot_4_2 = sns.pointplot(x='card5', y='Fraud', data=tmp2, \n",
        "                    color='black', order=list(tmp2.card5.values))\n",
        "plot_4_2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n",
        "plot_4.set_title(\"Card 5 Values Distribution and % of Transaction Frauds\", fontsize=20)\n",
        "plot_4.set_xticklabels(plot_4.get_xticklabels(),rotation=90)\n",
        "plot_4.set_xlabel(\"Card 5 Values\", fontsize=18)\n",
        "plot_4.set_ylabel(\"Count\", fontsize=18)\n",
        "for p in plot_4.patches:\n",
        "    height = p.get_height()\n",
        "    plot_4.text(p.get_x()+p.get_width()/2.,\n",
        "            height + 3,\n",
        "            '{:1.2f}%'.format(height/total*100),\n",
        "            ha=\"center\",fontsize=11) \n",
        "    \n",
        "plt.subplots_adjust(hspace = 0.6, top = 0.85)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRedjcgsp_BL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = pd.crosstab(train_transaction['card4'], train_transaction['isFraud'], normalize='index') * 100\n",
        "tmp = tmp.reset_index()\n",
        "tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
        "\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.suptitle('Card 4 Distributions', fontsize=22)\n",
        "\n",
        "plt.subplot(221)\n",
        "plot_1 = sns.countplot(x='card4', data=train_transaction)\n",
        "# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n",
        "plot_1.set_title(\"Card4 Distribution\", fontsize=19)\n",
        "plot_1.set_ylim(0,420000)\n",
        "plot_1.set_xlabel(\"Card4 Category Names\", fontsize=17)\n",
        "plot_1.set_ylabel(\"Count\", fontsize=17)\n",
        "for p in plot_1.patches:\n",
        "    height = p.get_height()\n",
        "    plot_1.text(p.get_x()+p.get_width()/2.,\n",
        "            height + 3,\n",
        "            '{:1.2f}%'.format(height/total*100),\n",
        "            ha=\"center\",fontsize=14) \n",
        "\n",
        "\n",
        "plt.subplot(222)\n",
        "plot_2 = sns.countplot(x='card4', hue='isFraud', data=train_transaction)\n",
        "plt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\n",
        "plot_2_2 = plot_1.twinx()\n",
        "plot_2_2 = sns.pointplot(x='card4', y='Fraud', data=tmp, \n",
        "                   color='black', legend=False, \n",
        "                   order=['discover', 'mastercard', 'visa', 'american express'])\n",
        "plot_2_2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n",
        "plot_2.set_title(\"Card4 by Target(isFraud)\", fontsize=19)\n",
        "plot_2.set_xlabel(\"Card4 Category Names\", fontsize=17)\n",
        "plot_2.set_ylabel(\"Count\", fontsize=17)\n",
        "\n",
        "plt.subplot(212)\n",
        "plot_3 = sns.boxenplot(x='card4', y='TransactionAmt', hue='isFraud', \n",
        "              data=train_transaction[train_transaction['TransactionAmt'] <= 2000] )\n",
        "plot_3.set_title(\"Card 4 Distribuition by ProductCD and Target\", fontsize=20)\n",
        "plot_3.set_xlabel(\"Card4 Category Names\", fontsize=17)\n",
        "plot_3.set_ylabel(\"Transaction Values\", fontsize=17)\n",
        "\n",
        "plt.subplots_adjust(hspace = 0.6, top = 0.85)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAojwOdTqC0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = pd.crosstab(train_transaction['card6'], train_transaction['isFraud'], normalize='index') * 100\n",
        "tmp = tmp.reset_index()\n",
        "tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
        "\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.suptitle('Card 6 Distributions', fontsize=22)\n",
        "\n",
        "plt.subplot(221)\n",
        "plot_1 = sns.countplot(x='card6', data=train_transaction, order=list(tmp.card6.values))\n",
        "# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n",
        "plot_1.set_title(\"Card6 Distribution\", fontsize=19)\n",
        "plot_1.set_ylim(0,480000)\n",
        "plot_1.set_xlabel(\"Card6 Category Names\", fontsize=17)\n",
        "plot_1.set_ylabel(\"Count\", fontsize=17)\n",
        "for p in plot_1.patches:\n",
        "    height = p.get_height()\n",
        "    plot_1.text(p.get_x()+p.get_width()/2.,\n",
        "            height + 3,\n",
        "            '{:1.2f}%'.format(height/total*100),\n",
        "            ha=\"center\",fontsize=14) \n",
        "\n",
        "plt.subplot(222)\n",
        "plot_2 = sns.countplot(x='card6', hue='isFraud', data=train_transaction, order=list(tmp.card6.values))\n",
        "plt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\n",
        "plot_2_2 = plot_2.twinx()\n",
        "plot_2_2 = sns.pointplot(x='card6', y='Fraud', data=tmp, order=list(tmp.card6.values),\n",
        "                   color='black', legend=False, )\n",
        "plot_2_2.set_ylim(0,20)\n",
        "plot_2_2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n",
        "plot_2.set_title(\"Card6 by Target(isFraud)\", fontsize=19)\n",
        "plot_2.set_xlabel(\"Card6 Category Names\", fontsize=17)\n",
        "plot_2.set_ylabel(\"Count\", fontsize=17)\n",
        "\n",
        "plt.subplot(212)\n",
        "plot_3 = sns.boxenplot(x='card6', y='TransactionAmt', hue='isFraud', order=list(tmp.card6.values),\n",
        "              data=train_transaction[train_transaction['TransactionAmt'] <= 2000] )\n",
        "plot_3.set_title(\"Card 6 Distribuition by ProductCD and Target\", fontsize=20)\n",
        "plot_3.set_xlabel(\"Card6 Category Names\", fontsize=17)\n",
        "plot_3.set_ylabel(\"Transaction Values\", fontsize=17)\n",
        "\n",
        "plt.subplots_adjust(hspace = 0.6, top = 0.85)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb5KRQfUqGYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for columns in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n",
        "    train_transaction[columns] = train_transaction[columns].fillna(\"Miss\")\n",
        "    \n",
        "def ploting_dist_ratio(DataFile, Column, lim=2000):\n",
        "    tmp = pd.crosstab(DataFile[Column], DataFile['isFraud'], normalize='index') * 100\n",
        "    tmp = tmp.reset_index()\n",
        "    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
        "\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.suptitle(f'{Column} Distributions ', fontsize=22)\n",
        "\n",
        "    plt.subplot(121)\n",
        "    plot_1 = sns.countplot(x=Column, data=DataFile, order=list(tmp[Column].values))\n",
        "    # plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n",
        "    plot_1.set_title(f\"{Column} Distribution\\nCound and %Fraud by each category\", fontsize=18)\n",
        "    plot_1.set_ylim(0,400000)\n",
        "    plot_1_2 = plot_1.twinx()\n",
        "    plot_1_2 = sns.pointplot(x=Column, y='Fraud', data=tmp, order=list(tmp[Column].values),\n",
        "                       color='black', legend=False, )\n",
        "    plot_1_2.set_ylim(0,20)\n",
        "    plot_1_2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n",
        "    plot_1.set_xlabel(f\"{Column} Category Names\", fontsize=16)\n",
        "    plot_1.set_ylabel(\"Count\", fontsize=17)\n",
        "    for p in plot_1_2.patches:\n",
        "        height = p.get_height()\n",
        "        plot_1_2.text(p.get_x()+p.get_width()/2.,\n",
        "                height + 3,\n",
        "                '{:1.2f}%'.format(height/total*100),\n",
        "                ha=\"center\",fontsize=14) \n",
        "        \n",
        "    perc_amt = (train_transaction.groupby(['isFraud',Column])['TransactionAmt'].sum() / total_amt * 100).unstack('isFraud')\n",
        "    perc_amt = perc_amt.reset_index()\n",
        "    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plot_2 = sns.boxplot(x=Column, y='TransactionAmt', hue='isFraud', \n",
        "                     data=DataFile[DataFile['TransactionAmt'] <= lim], order=list(tmp[Column].values))\n",
        "    plot_2_2 = plot_2.twinx()\n",
        "    plot_2_2 = sns.pointplot(x=Column, y='Fraud', data=perc_amt, order=list(tmp[Column].values),\n",
        "                       color='black', legend=False, )\n",
        "    plot_2_2.set_ylim(0,5)\n",
        "    plot_2_2.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n",
        "    plot_2.set_title(f\"{Column} by Transactions dist\", fontsize=18)\n",
        "    plot_2.set_xlabel(f\"{Column} Category Names\", fontsize=16)\n",
        "    plot_2.set_ylabel(\"Transaction Amount(U$)\", fontsize=16)\n",
        "        \n",
        "    plt.subplots_adjust(hspace=.4, wspace = 0.35, top = 0.80)\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FlswXtXqKwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for columns in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n",
        "    ploting_dist_ratio(train_transaction, columns, lim=2500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxY6x_3oqMtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transaction.loc[train_transaction.addr1.isin(train_transaction.addr1.value_counts()[train_transaction.addr1.value_counts() <= 5000 ].index), 'addr1'] = \"Others\"\n",
        "train_transaction.loc[train_transaction.addr2.isin(train_transaction.addr2.value_counts()[train_transaction.addr2.value_counts() <= 50 ].index), 'addr2'] = \"Others\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYnKNLulqTxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ploting_cnt_amt(DataFile, Column, lim=2000):\n",
        "    tmp = pd.crosstab(DataFile[Column], DataFile['isFraud'], normalize='index') * 100\n",
        "    tmp = tmp.reset_index()\n",
        "    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
        "    \n",
        "    plt.figure(figsize=(16,14))    \n",
        "    plt.suptitle(f'{Column} Distributions ', fontsize=24)\n",
        "    \n",
        "    plt.subplot(211)\n",
        "    plot_1 = sns.countplot(x=Column,data=DataFile,order=list(tmp[Column].values))\n",
        "    plot_1_2 = plot_1.twinx()\n",
        "    plot_1_2 = sns.pointplot(x=Column, y='Fraud', data=tmp, order=list(tmp[Column].values),\n",
        "                       color='black', legend=False)\n",
        "    plot_1_2.set_ylim(0,tmp['Fraud'].max()*1.1)\n",
        "    plot_1_2.set_ylabel(\"%Fraud Transactions\", fontsize=16)\n",
        "    plot_1.set_title(f\"Most Frequent {Column} values and % Fraud Transactions\", fontsize=20)\n",
        "    plot_1.set_xlabel(f\"{Column} Category Names\", fontsize=16)\n",
        "    plot_1.set_ylabel(\"Count\", fontsize=17)\n",
        "    plot_1.set_xticklabels(plot_1.get_xticklabels(),rotation=45)\n",
        "    sizes = []\n",
        "    for p in plot_1.patches:\n",
        "        height = p.get_height()\n",
        "        sizes.append(height)\n",
        "        plot_1.text(p.get_x()+p.get_width()/2.,\n",
        "                height + 3,\n",
        "                '{:1.2f}%'.format(height/total*100),\n",
        "                ha=\"center\",fontsize=12) \n",
        "        \n",
        "    plot_1.set_ylim(0,max(sizes)*1.15)\n",
        "    \n",
        "    #########################################################################\n",
        "    perc_amt = (DataFile.groupby(['isFraud',Column])['TransactionAmt'].sum() \\\n",
        "                / DataFile.groupby([Column])['TransactionAmt'].sum() * 100).unstack('isFraud')\n",
        "    perc_amt = perc_amt.reset_index()\n",
        "    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
        "    amt = DataFile.groupby([Column])['TransactionAmt'].sum().reset_index()\n",
        "    perc_amt = perc_amt.fillna(0)\n",
        "    plt.subplot(212)\n",
        "    plot_2 = sns.barplot(x=Column, y='TransactionAmt', \n",
        "                       data=amt, \n",
        "                       order=list(tmp[Column].values))\n",
        "    plot_2_2 = plot_2.twinx()\n",
        "    plot_2_2 = sns.pointplot(x=Column, y='Fraud', data=perc_amt, \n",
        "                        order=list(tmp[Column].values),\n",
        "                       color='black', legend=False, )\n",
        "    plot_2_2.set_ylim(0,perc_amt['Fraud'].max()*1.1)\n",
        "    plot_2_2.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n",
        "    plot_2.set_xticklabels(plot_2.get_xticklabels(),rotation=45)\n",
        "    plot_2.set_title(f\"{Column} by Transactions Total + %of total and %Fraud Transactions\", fontsize=20)\n",
        "    plot_2.set_xlabel(f\"{Column} Category Names\", fontsize=16)\n",
        "    plot_2.set_ylabel(\"Transaction Total Amount(U$)\", fontsize=16)\n",
        "    plot_2.set_xticklabels(plot_2.get_xticklabels(),rotation=45)    \n",
        "    \n",
        "    for p in plot_2.patches:\n",
        "        height = p.get_height()\n",
        "        plot_2.text(p.get_x()+p.get_width()/2.,\n",
        "                height + 3,\n",
        "                '{:1.2f}%'.format(height/total_amt*100),\n",
        "                ha=\"center\",fontsize=12) \n",
        "        \n",
        "    plt.subplots_adjust(hspace=.4, top = 0.9)\n",
        "    plt.show()\n",
        "    \n",
        "ploting_cnt_amt(train_transaction, 'addr1')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8tcbFlpqa1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ploting_cnt_amt(train_transaction, 'addr2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTit9sE8qdxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transaction.loc[train_transaction['P_emaildomain'].isin(['gmail.com', 'gmail']),'P_emaildomain'] = 'Google'\n",
        "\n",
        "train_transaction.loc[train_transaction['P_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n",
        "                                         'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n",
        "                                         'yahoo.es']), 'P_emaildomain'] = 'Yahoo Mail'\n",
        "train_transaction.loc[train_transaction['P_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n",
        "                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n",
        "                                         'outlook.es', 'live.com', 'live.fr',\n",
        "                                         'hotmail.fr']), 'P_emaildomain'] = 'Microsoft'\n",
        "train_transaction.loc[train_transaction.P_emaildomain.isin(train_transaction.P_emaildomain\\\n",
        "                                         .value_counts()[train_transaction.P_emaildomain.value_counts() <= 500 ]\\\n",
        "                                         .index), 'P_emaildomain'] = \"Others\"\n",
        "train_transaction.P_emaildomain.fillna(\"NoInf\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hprhcNzfqgOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ploting_cnt_amt(train_transaction, 'R_emaildomain')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnh4AW6fqied",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transaction.loc[train_transaction.C1.isin(train_transaction.C1\\\n",
        "                              .value_counts()[train_transaction.C1.value_counts() <= 400 ]\\\n",
        "                              .index), 'C1'] = \"Others\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "463l2xEfqkjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ploting_cnt_amt(train_transaction, 'C1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfyx22KXqmBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transaction.loc[train_transaction.C2.isin(train_transaction.C2\\\n",
        "                              .value_counts()[train_transaction.C2.value_counts() <= 350 ]\\\n",
        "                              .index), 'C2'] = \"Others\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKipdGlgqoap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ploting_cnt_amt(train_transaction, 'C2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJpcd31XqqKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/c/ieee-fraud-detection/discussion/100400#latest-579480\n",
        "import datetime\n",
        "\n",
        "START_DATE = '2017-12-01'\n",
        "startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
        "train_transaction[\"Date\"] = train_transaction['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
        "train_transaction['_Weekdays'] = train_transaction['Date'].dt.dayofweek\n",
        "train_transaction['_Hours'] = train_transaction['Date'].dt.hour\n",
        "train_transaction['_Days'] = train_transaction['Date'].dt.day\n",
        "\n",
        "test_transaction[\"Date\"] = test_transaction['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
        "test_transaction['_Weekdays'] = test_transaction['Date'].dt.dayofweek\n",
        "test_transaction['_Hours'] = test_transaction['Date'].dt.hour\n",
        "test_transaction['_Days'] = test_transaction['Date'].dt.day"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkaI31s2qtbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ploting_cnt_amt(train_transaction, '_Days')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NvOvMonqwpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ploting_cnt_amt(train_transaction, '_Weekdays')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J2-3N-BqyaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ploting_cnt_amt(train_transaction, '_Hours')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rij1-Cw9q0Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "from plotly.offline import iplot, init_notebook_mode\n",
        "#import cufflinks\n",
        "#import cufflinks as cf\n",
        "import plotly.figure_factory as ff\n",
        "# Calling the function to transform the date column in datetime pandas object\n",
        "\n",
        "#seting some static color options\n",
        "color_op = ['#5527A0', '#BB93D7', '#834CF7', '#6C941E', '#93EAEA', '#7425FF', '#F2098A', '#7E87AC', \n",
        "            '#EBE36F', '#7FD394', '#49C35D', '#3058EE', '#44FDCF', '#A38F85', '#C4CEE0', '#B63A05', \n",
        "            '#4856BF', '#F0DB1B', '#9FDBD9', '#B123AC']\n",
        "\n",
        "\n",
        "dates_temp = train_transaction.groupby(train_transaction.Date.dt.date)['TransactionAmt'].count().reset_index()\n",
        "# renaming the columns to apropriate names\n",
        "\n",
        "# creating the first trace with the necessary parameters\n",
        "trace = go.Scatter(x=dates_temp['Date'], y=dates_temp.TransactionAmt,\n",
        "                    opacity = 0.8, line = dict(color = color_op[7]), name= 'Total Transactions')\n",
        "\n",
        "# Below we will get the total amount sold\n",
        "dates_temp_sum = train_transaction.groupby(train_transaction.Date.dt.date)['TransactionAmt'].sum().reset_index()\n",
        "\n",
        "# using the new dates_temp_sum we will create the second trace\n",
        "trace1 = go.Scatter(x=dates_temp_sum.Date, line = dict(color = color_op[1]), name=\"Total Amount\",\n",
        "                        y=dates_temp_sum['TransactionAmt'], opacity = 0.8, yaxis='y2')\n",
        "\n",
        "#creating the layout the will allow us to give an title and \n",
        "# give us some interesting options to handle with the outputs of graphs\n",
        "layout = dict(\n",
        "    title= \"Total Transactions and Fraud Informations by Date\",\n",
        "    xaxis=dict(\n",
        "        rangeselector=dict(\n",
        "            buttons=list([\n",
        "                dict(count=1, label='1m', step='month', stepmode='backward'),\n",
        "                dict(count=3, label='3m', step='month', stepmode='backward'),\n",
        "                dict(count=6, label='6m', step='month', stepmode='backward'),\n",
        "                dict(step='all')\n",
        "            ])\n",
        "        ),\n",
        "        rangeslider=dict(visible = True),\n",
        "        type='date' ),\n",
        "    yaxis=dict(title='Total Transactions'),\n",
        "    yaxis2=dict(overlaying='y',\n",
        "                anchor='x', side='right',\n",
        "                zeroline=False, showgrid=False,\n",
        "                title='Total Transaction Amount')\n",
        ")\n",
        "\n",
        "# creating figure with the both traces and layout\n",
        "fig = dict(data= [trace, trace1,], layout=layout)\n",
        "\n",
        "#rendering the graphs\n",
        "iplot(fig) #it's an equivalent to plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyikA6Bgq-TE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calling the function to transform the date column in datetime pandas object\n",
        "\n",
        "#seting some static color options\n",
        "color_op = ['#5527A0', '#BB93D7', '#834CF7', '#6C941E', '#93EAEA', '#7425FF', '#F2098A', '#7E87AC', \n",
        "            '#EBE36F', '#7FD394', '#49C35D', '#3058EE', '#44FDCF', '#A38F85', '#C4CEE0', '#B63A05', \n",
        "            '#4856BF', '#F0DB1B', '#9FDBD9', '#B123AC']\n",
        "\n",
        "tmp_amt = train_transaction.groupby([train_transaction.Date.dt.date, 'isFraud'])['TransactionAmt'].sum().reset_index()\n",
        "tmp_trans = train_transaction.groupby([train_transaction.Date.dt.date, 'isFraud'])['TransactionAmt'].count().reset_index()\n",
        "\n",
        "tmp_trans_fraud = tmp_trans[tmp_trans['isFraud'] == 1]\n",
        "tmp_amt_fraud = tmp_amt[tmp_amt['isFraud'] == 1]\n",
        "\n",
        "dates_temp = train_transaction.groupby(train_transaction.Date.dt.date)['TransactionAmt'].count().reset_index()\n",
        "# renaming the columns to apropriate names\n",
        "\n",
        "# creating the first trace with the necessary parameters\n",
        "trace = go.Scatter(x=tmp_trans_fraud['Date'], y=tmp_trans_fraud.TransactionAmt,\n",
        "                    opacity = 0.8, line = dict(color = color_op[1]), name= 'Fraud Transactions')\n",
        "\n",
        "# using the new dates_temp_sum we will create the second trace\n",
        "trace1 = go.Scatter(x=tmp_amt_fraud.Date, line = dict(color = color_op[7]), name=\"Fraud Amount\",\n",
        "                    y=tmp_amt_fraud['TransactionAmt'], opacity = 0.8, yaxis='y2')\n",
        "\n",
        "#creating the layout the will allow us to give an title and \n",
        "# give us some interesting options to handle with the outputs of graphs\n",
        "layout = dict(\n",
        "    title= \"FRAUD TRANSACTIONS - Total Transactions and Fraud Informations by Date\",\n",
        "    xaxis=dict(\n",
        "        rangeselector=dict(\n",
        "            buttons=list([\n",
        "                dict(count=1, label='1m', step='month', stepmode='backward'),\n",
        "                dict(count=3, label='3m', step='month', stepmode='backward'),\n",
        "                dict(count=6, label='6m', step='month', stepmode='backward'),\n",
        "                dict(step='all')\n",
        "            ])\n",
        "        ),\n",
        "        rangeslider=dict(visible = True),\n",
        "        type='date' ),\n",
        "    yaxis=dict(title='Total Transactions'),\n",
        "    yaxis2=dict(overlaying='y',\n",
        "                anchor='x', side='right',\n",
        "                zeroline=False, showgrid=False,\n",
        "                title='Total Transaction Amount')\n",
        ")\n",
        "\n",
        "# creating figure with the both traces and layout\n",
        "fig = dict(data= [trace, trace1], layout=layout)\n",
        "\n",
        "#rendering the graphs\n",
        "iplot(fig) #it's an equivalent to plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q85V6fhOrIDJ",
        "colab_type": "text"
      },
      "source": [
        "##Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZclpVYlurEvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GroupKFold\n",
        "def seed_everything(seed=0):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceBruGRDrMGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "def make_predictions(tr_df, tt_df, features_columns, target, lgb_params, NFOLDS=6):\n",
        "    \n",
        "    folds = GroupKFold(n_splits=NFOLDS)\n",
        "\n",
        "    X,y = tr_df[features_columns], tr_df[target]    \n",
        "    P,P_y = tt_df[features_columns], tt_df[target]  \n",
        "    split_groups = tr_df['DT_M']\n",
        "\n",
        "    tt_df = tt_df[['TransactionID',target]]    \n",
        "    predictions = np.zeros(len(tt_df))\n",
        "    oof = np.zeros(len(tr_df))\n",
        "    \n",
        "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y, groups=split_groups)):\n",
        "        print('Fold:',fold_)\n",
        "        tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]\n",
        "        vl_x, vl_y = X.iloc[val_idx,:], y[val_idx]\n",
        "            \n",
        "        print(len(tr_x),len(vl_x))\n",
        "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
        "        vl_data = lgb.Dataset(vl_x, label=vl_y)  \n",
        "\n",
        "        estimator = lgb.train(\n",
        "            lgb_params,\n",
        "            tr_data,\n",
        "            valid_sets = [tr_data, vl_data],\n",
        "            verbose_eval = 200,\n",
        "        )   \n",
        "        \n",
        "        pp_p = estimator.predict(P)\n",
        "        predictions += pp_p/NFOLDS\n",
        "        \n",
        "        oof_preds = estimator.predict(vl_x)\n",
        "        oof[val_idx] = (oof_preds - oof_preds.min())/(oof_preds.max() - oof_preds.min())\n",
        "\n",
        "        if LOCAL_TEST:\n",
        "            feature_imp = pd.DataFrame(sorted(zip(estimator.feature_importance(),X.columns)), columns=['Value','Feature'])\n",
        "            print(feature_imp)\n",
        "        \n",
        "        del tr_x, tr_y, vl_x, vl_y, tr_data, vl_data\n",
        "        gc.collect()\n",
        "        \n",
        "    tt_df['prediction'] = predictions\n",
        "    print('OOF AUC:', metrics.roc_auc_score(y, oof))\n",
        "    if LOCAL_TEST:\n",
        "        print('Holdout AUC:', metrics.roc_auc_score(tt_df[TARGET], tt_df['prediction']))\n",
        "    \n",
        "    return tt_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_02jIoCdrPNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys, gc, warnings, random, datetime\n",
        "SEED = 42\n",
        "seed_everything(SEED)\n",
        "LOCAL_TEST = False\n",
        "TARGET = 'isFraud'\n",
        "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw8jYmbzr1I-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Load Data')\n",
        "train_df = pd.read_csv('train_transaction.csv')\n",
        "test_df = pd.read_csv('test_transaction.csv')\n",
        "test_df['isFraud'] = 0\n",
        "\n",
        "train_identity = pd.read_csv('train_identity.csv')\n",
        "test_identity = pd.read_csv('test_identity.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnPIPUVdsvqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for df in [train_df, test_df, train_identity, test_identity]:\n",
        "    original = df.copy()\n",
        "    df = reduce_mem_usage(df)\n",
        "\n",
        "    for col in list(df):\n",
        "        if df[col].dtype!='O':\n",
        "            if (df[col]-original[col]).sum()!=0:\n",
        "                df[col] = original[col]\n",
        "                print('Bad transformation', col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRGpczMLs0Eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in ['card4', 'card6', 'ProductCD']:\n",
        "    print('Encoding', col)\n",
        "    temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
        "    col_encoded = temp_df[col].value_counts().to_dict()   \n",
        "    train_df[col] = train_df[col].map(col_encoded)\n",
        "    test_df[col]  = test_df[col].map(col_encoded)\n",
        "    print(col_encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3i5MOZ5s4Ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in ['M1','M2','M3','M5','M6','M7','M8','M9']:\n",
        "    train_df[col] = train_df[col].map({'T':1, 'F':0})\n",
        "    test_df[col]  = test_df[col].map({'T':1, 'F':0})\n",
        "\n",
        "for col in ['M4']:\n",
        "    print('Encoding', col)\n",
        "    temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
        "    col_encoded = temp_df[col].value_counts().to_dict()   \n",
        "    train_df[col] = train_df[col].map(col_encoded)\n",
        "    test_df[col]  = test_df[col].map(col_encoded)\n",
        "    print(col_encoded)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWnB9bJFs5sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def minify_identity_df(df):\n",
        "\n",
        "    df['id_12'] = df['id_12'].map({'Found':1, 'NotFound':0})\n",
        "    df['id_15'] = df['id_15'].map({'New':2, 'Found':1, 'Unknown':0})\n",
        "    df['id_16'] = df['id_16'].map({'Found':1, 'NotFound':0})\n",
        "\n",
        "    df['id_23'] = df['id_23'].map({'TRANSPARENT':4, 'IP_PROXY':3, 'IP_PROXY:ANONYMOUS':2, 'IP_PROXY:HIDDEN':1})\n",
        "\n",
        "    df['id_27'] = df['id_27'].map({'Found':1, 'NotFound':0})\n",
        "    df['id_28'] = df['id_28'].map({'New':2, 'Found':1})\n",
        "\n",
        "    df['id_29'] = df['id_29'].map({'Found':1, 'NotFound':0})\n",
        "\n",
        "    df['id_35'] = df['id_35'].map({'T':1, 'F':0})\n",
        "    df['id_36'] = df['id_36'].map({'T':1, 'F':0})\n",
        "    df['id_37'] = df['id_37'].map({'T':1, 'F':0})\n",
        "    df['id_38'] = df['id_38'].map({'T':1, 'F':0})\n",
        "\n",
        "    df['id_34'] = df['id_34'].fillna(':0')\n",
        "    df['id_34'] = df['id_34'].apply(lambda x: x.split(':')[1]).astype(np.int8)\n",
        "    df['id_34'] = np.where(df['id_34']==0, np.nan, df['id_34'])\n",
        "    \n",
        "    df['id_33'] = df['id_33'].fillna('0x0')\n",
        "    df['id_33_0'] = df['id_33'].apply(lambda x: x.split('x')[0]).astype(int)\n",
        "    df['id_33_1'] = df['id_33'].apply(lambda x: x.split('x')[1]).astype(int)\n",
        "    df['id_33'] = np.where(df['id_33']=='0x0', np.nan, df['id_33'])\n",
        "\n",
        "    df['DeviceType'].map({'desktop':1, 'mobile':0})\n",
        "    return df\n",
        "\n",
        "train_identity = minify_identity_df(train_identity)\n",
        "test_identity = minify_identity_df(test_identity)\n",
        "\n",
        "for col in ['id_33']:\n",
        "    train_identity[col] = train_identity[col].fillna('unseen_before_label')\n",
        "    test_identity[col]  = test_identity[col].fillna('unseen_before_label')\n",
        "    \n",
        "    le = LabelEncoder()\n",
        "    le.fit(list(train_identity[col])+list(test_identity[col]))\n",
        "    train_identity[col] = le.transform(train_identity[col])\n",
        "    test_identity[col]  = le.transform(test_identity[col])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RZWX7Evs-GQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for df in [train_df, test_df, train_identity, test_identity]:\n",
        "    original = df.copy()\n",
        "    df = reduce_mem_usage(df)\n",
        "\n",
        "    for col in list(df):\n",
        "        if df[col].dtype!='O':\n",
        "            if (df[col]-original[col]).sum()!=0:\n",
        "                df[col] = original[col]\n",
        "                print('Bad transformation', col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc7QlJiItBiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.to_pickle('train_transaction_fixed.pkl')\n",
        "test_df.to_pickle('test_transaction_fixed.pkl')\n",
        "\n",
        "train_identity.to_pickle('train_identity_fixed.pkl')\n",
        "test_identity.to_pickle('test_identity_fixed.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETtWEXLQuWyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for df in [train_df, test_df, train_identity, test_identity]:\n",
        "    df = reduce_mem_usage(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob2BpDtcuby2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################### Export\n",
        "#################################################################################\n",
        "\n",
        "train_df.to_pickle('train_transaction.pkl')\n",
        "test_df.to_pickle('test_transaction.pkl')\n",
        "\n",
        "train_identity.to_pickle('train_identity.pkl')\n",
        "test_identity.to_pickle('test_identity.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGRagtVVrRJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Load Data')\n",
        "train_df = pd.read_pickle('train_transaction.pkl')\n",
        "\n",
        "if LOCAL_TEST:\n",
        "   \n",
        "    train_df['DT_M'] = train_df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
        "    train_df['DT_M'] = (train_df['DT_M'].dt.year-2017)*12 + train_df['DT_M'].dt.month \n",
        "    test_df = train_df[train_df['DT_M']==train_df['DT_M'].max()].reset_index(drop=True)\n",
        "    train_df = train_df[train_df['DT_M']<(train_df['DT_M'].max()-1)].reset_index(drop=True)\n",
        "    \n",
        "    train_identity = pd.read_pickle('train_identity.pkl')\n",
        "    test_identity  = train_identity[train_identity['TransactionID'].isin(\n",
        "                                    test_df['TransactionID'])].reset_index(drop=True)\n",
        "    train_identity = train_identity[train_identity['TransactionID'].isin(\n",
        "                                    train_df['TransactionID'])].reset_index(drop=True)\n",
        "    del train_df['DT_M'], test_df['DT_M']\n",
        "    \n",
        "else:\n",
        "    test_df = pd.read_pickle('test_transaction.pkl')\n",
        "    train_identity = pd.read_pickle('train_identity.pkl')\n",
        "    test_identity = pd.read_pickle('test_identity.pkl')\n",
        "    \n",
        "base_columns = list(train_df) + list(train_identity)\n",
        "print('Shape control:', train_df.shape, test_df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY4Bb9jJrTI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for df in [train_df, test_df]:\n",
        "\n",
        "    df['DT'] = df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
        "    df['DT_M'] = (df['DT'].dt.year-2017)*12 + df['DT'].dt.month\n",
        "    df['DT_W'] = (df['DT'].dt.year-2017)*52 + df['DT'].dt.weekofyear\n",
        "    df['DT_D'] = (df['DT'].dt.year-2017)*365 + df['DT'].dt.dayofyear\n",
        "    \n",
        "    df['DT_hour'] = df['DT'].dt.hour\n",
        "    df['DT_day_week'] = df['DT'].dt.dayofweek\n",
        "    df['DT_day'] = df['DT'].dt.day\n",
        "    \n",
        "    df['D9'] = np.where(df['D9'].isna(),0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSE9FinpujrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i_cols = ['card1']\n",
        "\n",
        "for col in i_cols: \n",
        "    valid_card = pd.concat([train_df[[col]], test_df[[col]]])\n",
        "    valid_card = valid_card[col].value_counts()\n",
        "    valid_card = valid_card[valid_card>2]\n",
        "    valid_card = list(valid_card.index)\n",
        "\n",
        "    train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)\n",
        "    test_df[col]  = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)\n",
        "\n",
        "    train_df[col] = np.where(train_df[col].isin(valid_card), train_df[col], np.nan)\n",
        "    test_df[col]  = np.where(test_df[col].isin(valid_card), test_df[col], np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJws_sPAuofz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i_cols = ['M1','M2','M3','M5','M6','M7','M8','M9']\n",
        "\n",
        "for df in [train_df, test_df]:\n",
        "    df['M_sum'] = df[i_cols].sum(axis=1).astype(np.int8)\n",
        "    df['M_na'] = df[i_cols].isna().sum(axis=1).astype(np.int8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpZjuwCkuq09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['uid'] = train_df['card1'].astype(str)+'_'+train_df['card2'].astype(str)\n",
        "test_df['uid'] = test_df['card1'].astype(str)+'_'+test_df['card2'].astype(str)\n",
        "\n",
        "train_df['uid2'] = train_df['uid'].astype(str)+'_'+train_df['card3'].astype(str)+'_'+train_df['card5'].astype(str)\n",
        "test_df['uid2'] = test_df['uid'].astype(str)+'_'+test_df['card3'].astype(str)+'_'+test_df['card5'].astype(str)\n",
        "\n",
        "train_df['uid3'] = train_df['uid2'].astype(str)+'_'+train_df['addr1'].astype(str)+'_'+train_df['addr2'].astype(str)\n",
        "test_df['uid3'] = test_df['uid2'].astype(str)+'_'+test_df['addr1'].astype(str)+'_'+test_df['addr2'].astype(str)\n",
        "\n",
        "train_df['TransactionAmt_check'] = np.where(train_df['TransactionAmt'].isin(test_df['TransactionAmt']), 1, 0)\n",
        "test_df['TransactionAmt_check']  = np.where(test_df['TransactionAmt'].isin(train_df['TransactionAmt']), 1, 0)\n",
        "\n",
        "i_cols = ['card1','card2','card3','card5','uid','uid2','uid3']\n",
        "\n",
        "for col in i_cols:\n",
        "    for agg_type in ['mean','std']:\n",
        "        new_col_name = col+'_TransactionAmt_'+agg_type\n",
        "        temp_df = pd.concat([train_df[[col, 'TransactionAmt']], test_df[[col,'TransactionAmt']]])\n",
        "        temp_df = temp_df.groupby([col])['TransactionAmt'].agg([agg_type]).reset_index().rename(\n",
        "                                                columns={agg_type: new_col_name})\n",
        "        \n",
        "        temp_df.index = list(temp_df[col])\n",
        "        temp_df = temp_df[new_col_name].to_dict()   \n",
        "    \n",
        "        train_df[new_col_name] = train_df[col].map(temp_df)\n",
        "        test_df[new_col_name]  = test_df[col].map(temp_df)\n",
        "           \n",
        "train_df['TransactionAmt'] = np.log1p(train_df['TransactionAmt'])\n",
        "test_df['TransactionAmt'] = np.log1p(test_df['TransactionAmt'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJYQm5A_ustI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = 'P_emaildomain'\n",
        "r = 'R_emaildomain'\n",
        "uknown = 'email_not_provided'\n",
        "\n",
        "for df in [train_df, test_df]:\n",
        "    df[p] = df[p].fillna(uknown)\n",
        "    df[r] = df[r].fillna(uknown)\n",
        "    \n",
        "    df['email_check'] = np.where((df[p]==df[r])&(df[p]!=uknown),1,0)\n",
        "\n",
        "    df[p+'_prefix'] = df[p].apply(lambda x: x.split('.')[0])\n",
        "    df[r+'_prefix'] = df[r].apply(lambda x: x.split('.')[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLeeDTGBuuoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for df in [train_identity, test_identity]:\n",
        "\n",
        "    df['DeviceInfo'] = df['DeviceInfo'].fillna('unknown_device').str.lower()\n",
        "    df['DeviceInfo_device'] = df['DeviceInfo'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
        "    df['DeviceInfo_version'] = df['DeviceInfo'].apply(lambda x: ''.join([i for i in x if i.isnumeric()]))\n",
        "    \n",
        "    df['id_30'] = df['id_30'].fillna('unknown_device').str.lower()\n",
        "    df['id_30_device'] = df['id_30'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
        "    df['id_30_version'] = df['id_30'].apply(lambda x: ''.join([i for i in x if i.isnumeric()]))\n",
        "    \n",
        "    df['id_31'] = df['id_31'].fillna('unknown_device').str.lower()\n",
        "    df['id_31_device'] = df['id_31'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2fyw2hTuw0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_df = train_df[['TransactionID']]\n",
        "temp_df = temp_df.merge(train_identity, on=['TransactionID'], how='left')\n",
        "del temp_df['TransactionID']\n",
        "train_df = pd.concat([train_df,temp_df], axis=1)\n",
        "    \n",
        "temp_df = test_df[['TransactionID']]\n",
        "temp_df = temp_df.merge(test_identity, on=['TransactionID'], how='left')\n",
        "del temp_df['TransactionID']\n",
        "test_df = pd.concat([test_df,temp_df], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0W0RoKWuy2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i_cols = ['card1','card2','card3','card5',\n",
        "          'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n",
        "          'D1','D2','D3','D4','D5','D6','D7','D8',\n",
        "          'addr1','addr2',\n",
        "          'dist1','dist2',\n",
        "          'P_emaildomain', 'R_emaildomain',\n",
        "          'DeviceInfo','DeviceInfo_device','DeviceInfo_version',\n",
        "          'id_30','id_30_device','id_30_version',\n",
        "          'id_31_device',\n",
        "          'id_33',\n",
        "          'uid','uid2','uid3',\n",
        "         ]\n",
        "\n",
        "for col in i_cols:\n",
        "    temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
        "    fq_encode = temp_df[col].value_counts(dropna=False).to_dict()   \n",
        "    train_df[col+'_fq_enc'] = train_df[col].map(fq_encode)\n",
        "    test_df[col+'_fq_enc']  = test_df[col].map(fq_encode)\n",
        "\n",
        "\n",
        "for col in ['DT_M','DT_W','DT_D']:\n",
        "    temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
        "    fq_encode = temp_df[col].value_counts().to_dict()\n",
        "            \n",
        "    train_df[col+'_total'] = train_df[col].map(fq_encode)\n",
        "    test_df[col+'_total']  = test_df[col].map(fq_encode)\n",
        "        \n",
        "\n",
        "periods = ['DT_M','DT_W','DT_D']\n",
        "i_cols = ['uid']\n",
        "for period in periods:\n",
        "    for col in i_cols:\n",
        "        new_column = col + '_' + period\n",
        "            \n",
        "        temp_df = pd.concat([train_df[[col,period]], test_df[[col,period]]])\n",
        "        temp_df[new_column] = temp_df[col].astype(str) + '_' + (temp_df[period]).astype(str)\n",
        "        fq_encode = temp_df[new_column].value_counts().to_dict()\n",
        "            \n",
        "        train_df[new_column] = (train_df[col].astype(str) + '_' + train_df[period].astype(str)).map(fq_encode)\n",
        "        test_df[new_column]  = (test_df[col].astype(str) + '_' + test_df[period].astype(str)).map(fq_encode)\n",
        "        \n",
        "        train_df[new_column] /= train_df[period+'_total']\n",
        "        test_df[new_column]  /= test_df[period+'_total']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4UvsCEqu1Dh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in list(train_df):\n",
        "    if train_df[col].dtype=='O':\n",
        "        print(col)\n",
        "        train_df[col] = train_df[col].fillna('unseen_before_label')\n",
        "        test_df[col]  = test_df[col].fillna('unseen_before_label')\n",
        "        \n",
        "        train_df[col] = train_df[col].astype(str)\n",
        "        test_df[col] = test_df[col].astype(str)\n",
        "        \n",
        "        le = LabelEncoder()\n",
        "        le.fit(list(train_df[col])+list(test_df[col]))\n",
        "        train_df[col] = le.transform(train_df[col])\n",
        "        test_df[col]  = le.transform(test_df[col])\n",
        "        \n",
        "        train_df[col] = train_df[col].astype('category')\n",
        "        test_df[col] = test_df[col].astype('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIpcIqpzu3mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rm_cols = [\n",
        "    'TransactionID','TransactionDT', # These columns are pure noise right now\n",
        "    TARGET,                          # Not target in features))\n",
        "    'uid','uid2','uid3',             # Our new client uID -> very noisy data\n",
        "    'bank_type',                     # Victims bank could differ by time\n",
        "    'DT','DT_M','DT_W','DT_D',       # Temporary Variables\n",
        "    'DT_hour','DT_day_week','DT_day',\n",
        "    'DT_D_total','DT_W_total','DT_M_total',\n",
        "    'id_30','id_31','id_33',\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtmeDrZku5XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################### Features elimination \n",
        "from scipy.stats import ks_2samp\n",
        "features_check = []\n",
        "columns_to_check = set(list(train_df)).difference(base_columns+rm_cols)\n",
        "for i in columns_to_check:\n",
        "    features_check.append(ks_2samp(test_df[i], train_df[i])[1])\n",
        "\n",
        "features_check = pd.Series(features_check, index=columns_to_check).sort_values() \n",
        "features_discard = list(features_check[features_check==0].index)\n",
        "print(features_discard)\n",
        "\n",
        "features_discard = [] \n",
        "\n",
        "# Final features list\n",
        "features_columns = [col for col in list(train_df) if col not in rm_cols + features_discard]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot1Hwubgu7k9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgb_params = {\n",
        "                'objective':'binary',\n",
        "                'boosting_type':'gbdt',\n",
        "                'metric':'auc',\n",
        "                'n_jobs':-1,\n",
        "                'learning_rate':0.01,\n",
        "                'num_leaves': 2**8,\n",
        "                'max_depth':-1,\n",
        "                'tree_learner':'serial',\n",
        "                'colsample_bytree': 0.85,\n",
        "                'subsample_freq':1,\n",
        "                'subsample':0.85,\n",
        "                'n_estimators':2**9,\n",
        "                'max_bin':255,\n",
        "                'verbose':-1,\n",
        "                'seed': SEED,\n",
        "                'early_stopping_rounds':100,\n",
        "                'reg_alpha':0.3,\n",
        "                'reg_lamdba':0.243\n",
        "            }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlaOoHwju-A_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if LOCAL_TEST:\n",
        "    lgb_params['learning_rate'] = 0.01\n",
        "    lgb_params['n_estimators'] = 20000\n",
        "    lgb_params['early_stopping_rounds'] = 100\n",
        "    test_predictions = make_predictions(train_df, test_df, features_columns, TARGET, lgb_params)\n",
        "    print(metrics.roc_auc_score(test_predictions[TARGET], test_predictions['prediction']))\n",
        "else:\n",
        "    lgb_params['learning_rate'] = 0.007\n",
        "    lgb_params['n_estimators'] = 1800\n",
        "    lgb_params['early_stopping_rounds'] = 100    \n",
        "    test_predictions = make_predictions(train_df, test_df, features_columns, TARGET, lgb_params, NFOLDS=6)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}